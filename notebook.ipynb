{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import wfdb\n",
    "import ast\n",
    "import time\n",
    "from itertools import chain\n",
    "from collections import Counter\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.graphics.tsaplots import acf\n",
    "import os\n",
    "import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.metrics import accuracy_score, auc, f1_score, roc_curve, RocCurveDisplay\n",
    "from preprocessing import preprocess_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 21799/21799 [03:34<00:00, 101.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropping other\n",
      "Filtering outliers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14538/14538 [00:16<00:00, 900.77it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying moving average\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13792/13792 [01:46<00:00, 129.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balancing data\n",
      "Train-test split\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = preprocess_data(path='plt')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обучение модели"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучение сети"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        fc_layers_size,\n",
    "        conv_layers\n",
    "    ) -> None:\n",
    "        super(ConvNet, self).__init__()\n",
    "        layers = []\n",
    "        in_channels = 12\n",
    "        conv_out_size = 1000\n",
    "        for kernel_size, out_channels, stride in conv_layers:\n",
    "            layers += [\n",
    "                nn.Conv1d(in_channels, out_channels, kernel_size, stride),\n",
    "                nn.ReLU(),\n",
    "                nn.MaxPool1d(2, 2)\n",
    "            ]\n",
    "            in_channels = out_channels\n",
    "            # for Conv1d\n",
    "            conv_out_size = self.conv_eval(conv_out_size, kernel_size, stride, 1)\n",
    "            # for MaxPool1d\n",
    "            conv_out_size = self.conv_eval(conv_out_size, 2, 2, 1)\n",
    "        layers.append(nn.Flatten())\n",
    "        features_in = conv_out_size * out_channels\n",
    "        for fc_out in fc_layers_size[:-1]:\n",
    "            layers += [\n",
    "                nn.Linear(features_in, fc_out),\n",
    "                nn.ReLU()\n",
    "            ]\n",
    "            features_in = fc_out\n",
    "        layers += [\n",
    "            nn.Linear(features_in, fc_layers_size[-1]),\n",
    "            nn.Sigmoid()\n",
    "        ]\n",
    "        self.seq = nn.Sequential(*layers)\n",
    "    \n",
    "    @classmethod\n",
    "    def conv_eval(self, len_in, kernel_size, stride, dilation):\n",
    "        return int((len_in - 1 - dilation * (kernel_size - 1)) / stride + 1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.seq(x)\n",
    "    \n",
    "    def train_net(\n",
    "        self,\n",
    "        criterion,\n",
    "        optimizer,\n",
    "        objects,\n",
    "        labels,\n",
    "        epochs,\n",
    "        batch_size\n",
    "    ):\n",
    "        objects = torch.Tensor(objects)\n",
    "        labels = torch.Tensor(np.array([labels]).T)\n",
    "        dataset = TensorDataset(objects, labels)\n",
    "        dataloader = DataLoader(dataset, batch_size, shuffle=True)\n",
    "        test_accuracy_list = [0]\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            loss_value = 0.0\n",
    "            for i, batch in enumerate(dataloader):\n",
    "                inputs, labels = batch[0].to(device, non_blocking=True), batch[1].to(device, non_blocking=True)\n",
    "                optimizer.zero_grad()\n",
    "                outputs = self(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                loss_value += loss.item()\n",
    "            train_accuracy = accuracy_score(\n",
    "                y_train,#.to(device, non_blocking=True), \n",
    "                [(1 if pred[0] > 0.5 else 0) for pred in self.test(torch.Tensor(x_train).to(device, non_blocking=True))]\n",
    "            )\n",
    "            test_accuracy = accuracy_score(\n",
    "                y_test,#.to(device, non_blocking=True), \n",
    "                [(1 if pred[0] > 0.5 else 0) for pred in self.test(torch.Tensor(x_test).to(device, non_blocking=True))]\n",
    "            )\n",
    "            test_accuracy_list.append(test_accuracy)\n",
    "            print(f'Epoch {epoch:5} loss = {loss_value:.4f} Train: {train_accuracy:.4f} Test {test_accuracy:.4f}')\n",
    "            #if epoch > 5 and np.average(test_accuracy_list[-4:]) < test_accuracy_list[-5]:\n",
    "            #    print('Test accuracy decreasing, break')\n",
    "            #    break\n",
    "    \n",
    "    def test(self, samples):\n",
    "        with torch.no_grad():\n",
    "            return self.forward(torch.Tensor(samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch     0 loss = 35.1395 Train: 0.7318 Test 0.7309\n",
      "Epoch     1 loss = 24.8638 Train: 0.8332 Test 0.8288\n",
      "Epoch     2 loss = 20.2137 Train: 0.8507 Test 0.8388\n",
      "Epoch     3 loss = 17.9933 Train: 0.8697 Test 0.8603\n",
      "Epoch     4 loss = 17.1632 Train: 0.8808 Test 0.8679\n",
      "Epoch     5 loss = 16.0666 Train: 0.8854 Test 0.8726\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 11\u001b[0m\n\u001b[0;32m      9\u001b[0m generated\n\u001b[0;32m     10\u001b[0m generated\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m---> 11\u001b[0m generated\u001b[39m.\u001b[39;49mtrain_net(\n\u001b[0;32m     12\u001b[0m     nn\u001b[39m.\u001b[39;49mBCELoss(), \n\u001b[0;32m     13\u001b[0m     optim\u001b[39m.\u001b[39;49mAdam(generated\u001b[39m.\u001b[39;49mparameters(), lr\u001b[39m=\u001b[39;49m\u001b[39m0.0001\u001b[39;49m),\n\u001b[0;32m     14\u001b[0m     x_train, \n\u001b[0;32m     15\u001b[0m     y_train, \n\u001b[0;32m     16\u001b[0m     \u001b[39m30\u001b[39;49m, \n\u001b[0;32m     17\u001b[0m     \u001b[39m128\u001b[39;49m\n\u001b[0;32m     18\u001b[0m )\n",
      "Cell \u001b[1;32mIn[4], line 63\u001b[0m, in \u001b[0;36mConvNet.train_net\u001b[1;34m(self, criterion, optimizer, objects, labels, epochs, batch_size)\u001b[0m\n\u001b[0;32m     61\u001b[0m inputs, labels \u001b[39m=\u001b[39m batch[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mto(device, non_blocking\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m), batch[\u001b[39m1\u001b[39m]\u001b[39m.\u001b[39mto(device, non_blocking\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m     62\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[1;32m---> 63\u001b[0m outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m(inputs)\n\u001b[0;32m     64\u001b[0m loss \u001b[39m=\u001b[39m criterion(outputs, labels)\n\u001b[0;32m     65\u001b[0m loss\u001b[39m.\u001b[39mbackward()\n",
      "File \u001b[1;32mc:\\Users\\user\\PycharmProjects\\ml\\project\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "Cell \u001b[1;32mIn[4], line 41\u001b[0m, in \u001b[0;36mConvNet.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[1;32m---> 41\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mseq(x)\n",
      "File \u001b[1;32mc:\\Users\\user\\PycharmProjects\\ml\\project\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\user\\PycharmProjects\\ml\\project\\venv\\lib\\site-packages\\torch\\nn\\modules\\container.py:204\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    202\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[0;32m    203\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[1;32m--> 204\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[0;32m    205\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\user\\PycharmProjects\\ml\\project\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\user\\PycharmProjects\\ml\\project\\venv\\lib\\site-packages\\torch\\nn\\modules\\conv.py:313\u001b[0m, in \u001b[0;36mConv1d.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    312\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m--> 313\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_conv_forward(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "File \u001b[1;32mc:\\Users\\user\\PycharmProjects\\ml\\project\\venv\\lib\\site-packages\\torch\\nn\\modules\\conv.py:309\u001b[0m, in \u001b[0;36mConv1d._conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    305\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mzeros\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m    306\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39mconv1d(F\u001b[39m.\u001b[39mpad(\u001b[39minput\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode),\n\u001b[0;32m    307\u001b[0m                     weight, bias, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstride,\n\u001b[0;32m    308\u001b[0m                     _single(\u001b[39m0\u001b[39m), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdilation, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgroups)\n\u001b[1;32m--> 309\u001b[0m \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mconv1d(\u001b[39minput\u001b[39;49m, weight, bias, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstride,\n\u001b[0;32m    310\u001b[0m                 \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpadding, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdilation, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgroups)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "generated = ConvNet(\n",
    "    fc_layers_size=[500, 1],\n",
    "    conv_layers=[\n",
    "        (7, 48, 2),\n",
    "        (5, 144, 2),\n",
    "        (5, 288, 2),\n",
    "    ]\n",
    ")\n",
    "generated\n",
    "generated.to(device)\n",
    "generated.train_net(\n",
    "    nn.BCELoss(), \n",
    "    optim.Adam(generated.parameters(), lr=0.0001),\n",
    "    x_train, \n",
    "    y_train, \n",
    "    30, \n",
    "    128\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4 (tags/v3.10.4:9d38120, Mar 23 2022, 23:13:41) [MSC v.1929 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "78af1032024918b445cdfc1abaa658cd5e1d9c5ffc34bc659ce1504737297de4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
